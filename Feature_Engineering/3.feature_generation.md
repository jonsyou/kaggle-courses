[tutorial_url](https://www.kaggle.com/matleonard/feature-generation)

# Feature Generation

Creating new features from the raw data is one of the best ways to improve your model. The features you create are different for every dataset, so it takes a bit of creativity and experimentation. 

## Interactions

One of the easiest ways to create new features is by combining categorical variables. For example, if one record has the country "CA" and category "Music", you can create a new value "CA_Music". This is a new categorical feature that can provide information about correlations between categorical variables. This type of feature is typically called an interaction.

In general, you would build interaction features from all pairs of categorical features. You can make interactions from three or more features as well, but you'll tend to get diminishing returns.

```python
interactions = ks['category'] + "_" + ks['country']
print(interactions.head(5))

[output]
'''
0            Poetry_GB
1    Narrative Film_US
2    Narrative Film_US
3             Music_US
4      Film & Video_US
dtype: object
'''
```

Then, we can label encode the interaction feature and add it to our data.

```python
label_enc = LabelEncoder()
data_interaction = baseline_data.assign(category_country=label_enc.fit_transform(interactions))
data_interaction.head()
```

	goal	hour	day	month	year	outcome	category	currency	country	category_country
0	1000.0	12	11	8	2015	0	108	5	9	1900
1	30000.0	4	2	9	2017	0	93	13	22	1630
2	45000.0	0	12	1	2013	0	93	13	22	1630
3	5000.0	3	17	3	2012	0	90	13	22	1595
4	19500.0	8	4	7	2015	0	55	13	22	979

## Number of projects in the last week

Next, we'll count the number of projects launched in the preceeding week for each record. I'll use the ```.rolling``` method on a series with the ```"launched"``` column as the index. I'll create the series, using ```ks.launched``` as the index and ```ks.index``` as the values, then sort the times. Using a time series as the index allows us to define the rolling window size in terms of hours, days, weeks, etc.

```python
# First, create a Series with a timestamp index
launched = pd.Series(ks.index, index=ks.launched, name="count_7_days").sort_index()
launched.head(20)

[output]
'''
launched
1970-01-01 01:00:00     94579
1970-01-01 01:00:00    319002
1970-01-01 01:00:00    247913
1970-01-01 01:00:00     48147
1970-01-01 01:00:00     75397
1970-01-01 01:00:00      2842
1970-01-01 01:00:00    273779
2009-04-21 21:02:48    169268
2009-04-23 00:07:53    322000
2009-04-24 21:52:03    138572
2009-04-25 17:36:21    325391
2009-04-27 14:10:39    122662
2009-04-28 13:55:41    213711
2009-04-29 02:04:21    345606
2009-04-29 02:58:50    235255
2009-04-29 04:37:37     98954
2009-04-29 05:26:32    342226
2009-04-29 06:43:44    275091
2009-04-29 13:52:03    284115
2009-04-29 22:08:13     32898
Name: count_7_days, dtype: int64
'''
```

With a timeseries index, you can use .rolling to select time periods as the window. For example launched.rolling('7d') creates a rolling window that contains all the data in the previous 7 days. The window contains the current record, so if we want to count all the previous projects but not the current one, we'll need to subtract 1. We'll plot the results to make sure it looks right.

```python
count_7_days = launched.rolling('7d').count() - 1
print(count_7_days.head(20))

# Ignore records with broken launch dates
plt.plot(count_7_days[7:]);
plt.title("Number of projects launched over periods of 7 days");

[output]
'''
launched
1970-01-01 01:00:00     0.0
1970-01-01 01:00:00     1.0
1970-01-01 01:00:00     2.0
1970-01-01 01:00:00     3.0
1970-01-01 01:00:00     4.0
1970-01-01 01:00:00     5.0
1970-01-01 01:00:00     6.0
2009-04-21 21:02:48     0.0
2009-04-23 00:07:53     1.0
2009-04-24 21:52:03     2.0
2009-04-25 17:36:21     3.0
2009-04-27 14:10:39     4.0
2009-04-28 13:55:41     5.0
2009-04-29 02:04:21     5.0
2009-04-29 02:58:50     6.0
2009-04-29 04:37:37     7.0
2009-04-29 05:26:32     8.0
2009-04-29 06:43:44     9.0
2009-04-29 13:52:03    10.0
2009-04-29 22:08:13    11.0
Name: count_7_days, dtype: float64
'''
```

![image](https://user-images.githubusercontent.com/74973306/104890971-a5c37400-59b3-11eb-87a0-7f56eb826f6a.png)

Now that we have the counts, we need to adjust the index so we can join it with the other training data.

```python
count_7_days.index = launched.values
count_7_days = count_7_days.reindex(ks.index)
```

```python
count_7_days.head(10)

[output]
'''
0    1409.0
1     957.0
2     739.0
3     907.0
4    1429.0
5    1284.0
6    1119.0
7    1391.0
8    1043.0
9    3199.0
Name: count_7_days, dtype: float64
'''
```

Now join the new feature with the other data again using ```.join``` since we've matched the index.

```python
baseline_data.join(count_7_days).head(10)
```

goal	hour	day	month	year	outcome	category	currency	country	count_7_days
0	1000.0	12	11	8	2015	0	108	5	9	1409.0
1	30000.0	4	2	9	2017	0	93	13	22	957.0
2	45000.0	0	12	1	2013	0	93	13	22	739.0
3	5000.0	3	17	3	2012	0	90	13	22	907.0
4	19500.0	8	4	7	2015	0	55	13	22	1429.0
5	50000.0	13	26	2	2016	1	123	13	22	1284.0
6	1000.0	18	1	12	2014	1	58	13	22	1119.0
7	25000.0	20	1	2	2016	0	41	13	22	1391.0
8	125000.0	18	24	4	2014	0	113	13	22	1043.0
9	65000.0	21	11	7	2014	0	39	13	22	3199.0

## Time since the last project in the same category

