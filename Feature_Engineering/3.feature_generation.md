[tutorial_url](https://www.kaggle.com/matleonard/feature-generation)

# Feature Generation

Creating new features from the raw data is one of the best ways to improve your model. The features you create are different for every dataset, so it takes a bit of creativity and experimentation. 

## Interactions

One of the easiest ways to create new features is by combining categorical variables. For example, if one record has the country "CA" and category "Music", you can create a new value "CA_Music". This is a new categorical feature that can provide information about correlations between categorical variables. This type of feature is typically called an interaction.

In general, you would build interaction features from all pairs of categorical features. You can make interactions from three or more features as well, but you'll tend to get diminishing returns.

```python
interactions = ks['category'] + "_" + ks['country']
print(interactions.head(5))

[output]
'''
0            Poetry_GB
1    Narrative Film_US
2    Narrative Film_US
3             Music_US
4      Film & Video_US
dtype: object
'''
```

Then, we can label encode the interaction feature and add it to our data.

```python
label_enc = LabelEncoder()
data_interaction = baseline_data.assign(category_country=label_enc.fit_transform(interactions))
data_interaction.head()
```

	goal	hour	day	month	year	outcome	category	currency	country	category_country
0	1000.0	12	11	8	2015	0	108	5	9	1900
1	30000.0	4	2	9	2017	0	93	13	22	1630
2	45000.0	0	12	1	2013	0	93	13	22	1630
3	5000.0	3	17	3	2012	0	90	13	22	1595
4	19500.0	8	4	7	2015	0	55	13	22	979

## Number of projects in the last week

Next, we'll count the number of projects launched in the preceeding week for each record. I'll use the ```.rolling``` method on a series with the ```"launched"``` column as the index. I'll create the series, using ```ks.launched``` as the index and ```ks.index``` as the values, then sort the times. Using a time series as the index allows us to define the rolling window size in terms of hours, days, weeks, etc.

```python
# First, create a Series with a timestamp index
launched = pd.Series(ks.index, index=ks.launched, name="count_7_days").sort_index()
launched.head(20)

[output]
'''
launched
1970-01-01 01:00:00     94579
1970-01-01 01:00:00    319002
1970-01-01 01:00:00    247913
1970-01-01 01:00:00     48147
1970-01-01 01:00:00     75397
1970-01-01 01:00:00      2842
1970-01-01 01:00:00    273779
2009-04-21 21:02:48    169268
2009-04-23 00:07:53    322000
2009-04-24 21:52:03    138572
2009-04-25 17:36:21    325391
2009-04-27 14:10:39    122662
2009-04-28 13:55:41    213711
2009-04-29 02:04:21    345606
2009-04-29 02:58:50    235255
2009-04-29 04:37:37     98954
2009-04-29 05:26:32    342226
2009-04-29 06:43:44    275091
2009-04-29 13:52:03    284115
2009-04-29 22:08:13     32898
Name: count_7_days, dtype: int64
'''
```

With a timeseries index, you can use .rolling to select time periods as the window. For example launched.rolling('7d') creates a rolling window that contains all the data in the previous 7 days. The window contains the current record, so if we want to count all the previous projects but not the current one, we'll need to subtract 1. We'll plot the results to make sure it looks right.

```python
count_7_days = launched.rolling('7d').count() - 1
print(count_7_days.head(20))

# Ignore records with broken launch dates
plt.plot(count_7_days[7:]);
plt.title("Number of projects launched over periods of 7 days");

[output]
'''
launched
1970-01-01 01:00:00     0.0
1970-01-01 01:00:00     1.0
1970-01-01 01:00:00     2.0
1970-01-01 01:00:00     3.0
1970-01-01 01:00:00     4.0
1970-01-01 01:00:00     5.0
1970-01-01 01:00:00     6.0
2009-04-21 21:02:48     0.0
2009-04-23 00:07:53     1.0
2009-04-24 21:52:03     2.0
2009-04-25 17:36:21     3.0
2009-04-27 14:10:39     4.0
2009-04-28 13:55:41     5.0
2009-04-29 02:04:21     5.0
2009-04-29 02:58:50     6.0
2009-04-29 04:37:37     7.0
2009-04-29 05:26:32     8.0
2009-04-29 06:43:44     9.0
2009-04-29 13:52:03    10.0
2009-04-29 22:08:13    11.0
Name: count_7_days, dtype: float64
'''
```

![image](https://user-images.githubusercontent.com/74973306/104890971-a5c37400-59b3-11eb-87a0-7f56eb826f6a.png)

Now that we have the counts, we need to adjust the index so we can join it with the other training data.

```python
count_7_days.index = launched.values
count_7_days = count_7_days.reindex(ks.index)
```

```python
count_7_days.head(10)

[output]
'''
0    1409.0
1     957.0
2     739.0
3     907.0
4    1429.0
5    1284.0
6    1119.0
7    1391.0
8    1043.0
9    3199.0
Name: count_7_days, dtype: float64
'''
```

Now join the new feature with the other data again using ```.join``` since we've matched the index.

```python
baseline_data.join(count_7_days).head(10)
```

goal	hour	day	month	year	outcome	category	currency	country	count_7_days
0	1000.0	12	11	8	2015	0	108	5	9	1409.0
1	30000.0	4	2	9	2017	0	93	13	22	957.0
2	45000.0	0	12	1	2013	0	93	13	22	739.0
3	5000.0	3	17	3	2012	0	90	13	22	907.0
4	19500.0	8	4	7	2015	0	55	13	22	1429.0
5	50000.0	13	26	2	2016	1	123	13	22	1284.0
6	1000.0	18	1	12	2014	1	58	13	22	1119.0
7	25000.0	20	1	2	2016	0	41	13	22	1391.0
8	125000.0	18	24	4	2014	0	113	13	22	1043.0
9	65000.0	21	11	7	2014	0	39	13	22	3199.0

## Time since the last project in the same category

A handy method for performing operations within groups is to use ```.groupby``` then ```.transform```. The ```.transform``` method takes a function then passes a series or dataframe to that function for each group. This returns a dataframe with the same indices as the original dataframe.

```python
def time_since_last_project(series):
    # Return the time in hours
    return series.diff().dt.total_seconds() / 3600.

df = ks[['category', 'launched']].sort_values('launched')
timedeltas = df.groupby('category').transform(time_since_last_project)
timedeltas.head(20)
```
	launched
94579	NaN
319002	NaN
247913	NaN
48147	NaN
75397	NaN
2842	0.000000
273779	NaN
169268	NaN
322000	NaN
138572	NaN
325391	NaN
122662	137.130833
213711	NaN
345606	145.941111
235255	NaN
98954	344715.626944
342226	NaN
275091	NaN
284115	NaN
32898	NaN

We get ```NaN```s here for projects that are the first in their category. We'll need to fill those in with something like the mean or median. We'll also need to reset the index so we can join it with the other data.

```python
# Final time since last project
timedeltas = timedeltas.fillna(timedeltas.median()).reindex(baseline_data.index)
timedeltas.head(20)
```
	launched
0	18.606111
1	5.592778
2	1.313611
3	0.635000
4	16.661389
5	2.629722
6	0.367500
7	12.286111
8	14.243611
9	0.174722
10	1.372222
11	8.524444
12	0.015833
13	9.884444
14	1.725556
15	3.806111
16	2.654167
17	26.531667
18	12.273611
19	9.288889

## Transforming numerical features

Some models work better when the features are normally distributed, so it might help to transform the goal values. Common choices for this are the square root and natural logarithm. These transformations can also help constrain outliers.

```python
plt.hist(ks.goal, range=(0, 100000), bins=50);
plt.title('Goal');
```

![image](https://user-images.githubusercontent.com/74973306/105130561-9e72a680-5b2a-11eb-81bd-238c0e6ca0b9.png)

```python
plt.hist(np.sqrt(ks.goal), range=(0, 400), bins=50);
plt.title('Sqrt(Goal)');
```

![image](https://user-images.githubusercontent.com/74973306/105130613-b4806700-5b2a-11eb-905e-e3651918d2bd.png)

```python
plt.hist(np.log(ks.goal), range=(0, 25), bins=50);
plt.title('Log(Goal)');
```

![image](https://user-images.githubusercontent.com/74973306/105130644-c3671980-5b2a-11eb-8bb5-826653042b31.png)

The log transformation won't help our model since tree-based models are scale invariant. However, this should help if we had a linear model or neural network.

Other transformations include squares and other powers, exponentials, etc. These might help the model discriminate, like the kernel trick for SVMs. Again, it takes a bit of experimentation to see what works. One method is to create a bunch of new features and later choose the best ones with feature selection algorithms.

---

## Exercise

```python
import numpy as np
import pandas as pd
from sklearn import preprocessing, metrics
import lightgbm as lgb

# Create features from   timestamps
click_data = pd.read_csv('../input/feature-engineering-data/train_sample.csv', 
                         parse_dates=['click_time'])
click_times = click_data['click_time']
clicks = click_data.assign(day=click_times.dt.day.astype('uint8'),
                           hour=click_times.dt.hour.astype('uint8'),
                           minute=click_times.dt.minute.astype('uint8'),
                           second=click_times.dt.second.astype('uint8'))

# Label encoding for categorical features
cat_features = ['ip', 'app', 'device', 'os', 'channel']
for feature in cat_features:
    label_encoder = preprocessing.LabelEncoder()
    clicks[feature] = label_encoder.fit_transform(clicks[feature])
    
def get_data_splits(dataframe, valid_fraction=0.1):

    dataframe = dataframe.sort_values('click_time')
    valid_rows = int(len(dataframe) * valid_fraction)
    train = dataframe[:-valid_rows * 2]
    # valid size == test size, last two sections of the data
    valid = dataframe[-valid_rows * 2:-valid_rows]
    test = dataframe[-valid_rows:]
    
    return train, valid, test

def train_model(train, valid, test=None, feature_cols=None):
    if feature_cols is None:
        feature_cols = train.columns.drop(['click_time', 'attributed_time',
                                           'is_attributed'])
    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])
    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])
    
    param = {'num_leaves': 64, 'objective': 'binary', 
             'metric': 'auc', 'seed': 7}
    num_round = 1000
    print("Training model. Hold on a minute to see the validation score")
    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], 
                    early_stopping_rounds=20, verbose_eval=False)
    
    valid_pred = bst.predict(valid[feature_cols])
    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)
    print(f"Validation AUC score: {valid_score}")
    
    if test is not None: 
        test_pred = bst.predict(test[feature_cols])
        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)
        return bst, valid_score, test_score
    else:
        return bst, valid_score

print("Baseline model score")
train, valid, test = get_data_splits(clicks)
_ = train_model(train, valid)

[output]
'''
Baseline model score
Training model. Hold on a minute to see the validation score
Validation AUC score: 0.9622743228943659
'''
```

### 1) Add interaction features

```python
import itertools

cat_features = ['ip', 'app', 'device', 'os', 'channel']
interactions = pd.DataFrame(index=clicks.index)
for col1, col2 in itertools.combinations(cat_features, 2):
    new_col_name = '_'.join([col1, col2])

    # Convert to strings and combine
    new_values = clicks[col1].map(str) + "_" + clicks[col2].map(str)

    encoder = preprocessing.LabelEncoder()
    interactions[new_col_name] = encoder.fit_transform(new_values)
```
>> interactions

	ip_app	ip_device	ip_os	ip_channel	app_device	app_os	app_channel	device_os	device_channel	os_channel
0	492097	219682	496314	681060	3631	4100	675	1229	1890	985
1	40669	14419	39852	57863	3581	3849	625	1229	1867	962
2	19984	6955	19603	28875	4196	5045	787	1229	1928	1018
3	784442	300967	792039	1140313	3631	4100	675	1229	1890	985
4	714088	274929	722619	1041993	3631	4100	675	1229	1890	985
...	...	...	...	...	...	...	...	...	...	...
2300556	869529	331925	876635	1261351	3474	3473	542	1282	1937	2239
2300557	732095	281479	740361	1067079	1177	1191	168	1229	1917	1009
2300558	172291	70732	172020	239696	748	693	96	1590	2565	1936
2300559	22264	7800	21904	32170	744	687	93	1248	1979	1512
2300560	127175	50148	126240	178396	5203	5843	872	1282	1973	2273

```python
clicks = clicks.join(interactions)
print("Score with interactions")
train, valid, test = get_data_splits(clicks)
_ = train_model(train, valid)

[output]
'''
Score with interactions
Training model. Hold on a minute to see the validation score
Validation AUC score: 0.9626212895350978
'''
```

## Generating numerical features

Adding interactions is a quick way to create more categorical features from the data. It's also effective to create new numerical features, you'll typically get a lot of improvement in the model. This takes a bit of brainstorming and experimentation to find features that work well.

### 2) Number of events in the past six hours

The first feature you'll be creating is the number of events from the same IP in the last six hours. It's likely that someone who is visiting often will download the app.

```python
def count_past_events(series):
    series = pd.Series(series.index, index=series)
    # Subtract 1 so the current event isn't counted
    past_events = series.rolling('6h').count() - 1
    return past_events
```

Because this can take a while to calculate on the full data, we'll load pre-calculated versions in the cell below to test model performance.

```python
# Loading in from saved Parquet file
past_events = pd.read_parquet('../input/feature-engineering-data/past_6hr_events.pqt')
clicks['ip_past_6hr_counts'] = past_events

train, valid, test = get_data_splits(clicks)
_ = train_model(train, valid)

[output]
'''
Training model. Hold on a minute to see the validation score
Validation AUC score: 0.9647255487084245
'''
```

### 3) Features from future information

In general, you shouldn't use information from the future. When you're using models like this in a real-world scenario you won't have data from the future. Your model's score will likely be higher when training and testing on historical data, but it will overestimate the performance on real data. 

### 4) Time since last event

Implement a function time_diff that calculates the time since the last event in seconds from a Series of timestamps.

```python
timedeltas = clicks.groupby('ip')['click_time'].transform(time_diff)
```

```python
def time_diff(series):
    return series.diff().dt.total_seconds()
```

We'll again load pre-computed versions of the data, which match what your function would return

```python
# Loading in from saved Parquet file
past_events = pd.read_parquet('../input/feature-engineering-data/time_deltas.pqt')
clicks['past_events_6hr'] = past_events

train, valid, test = get_data_splits(clicks.join(past_events))
_ = train_model(train, valid)

[output]
'''
Training model. Hold on a minute to see the validation score
Validation AUC score: 0.9651116624672765
'''
```

### 5) Number of previous app downloads

It's likely that if a visitor downloaded an app previously, it'll affect the likelihood they'll download one again. Implement a function ```previous_attributions``` that returns a Series with the number of times an app has been downloaded (```'is_attributed' == 1```) before the current event.

```python
def previous_attributions(series):
    # Subtracting raw values so I don't count the current event
    sums = series.expanding(min_periods=2).sum() - series
    return sums
```

Again loading pre-computed data.

```python
# Loading in from saved Parquet file
past_events = pd.read_parquet('../input/feature-engineering-data/downloads.pqt')
clicks['ip_past_6hr_counts'] = past_events

train, valid, test = get_data_splits(clicks)
_ = train_model(train, valid)

[output]
'''
Training model. Hold on a minute to see the validation score
Validation AUC score: 0.965236652054989
'''
```

### 6) Tree-based vs Neural Network Models

The features themselves will work for either model. However, numerical inputs to neural networks need to be standardized first. That is, the features need to be scaled such that they have 0 mean and a standard deviation of 1. This can be done using sklearn.preprocessing.StandardScaler.

