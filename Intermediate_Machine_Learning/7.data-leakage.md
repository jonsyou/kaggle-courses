[tutorial url](https://www.kaggle.com/alexisbcook/data-leakage)

# Data Leakage

**Data leakage** (or **leakage**) happens when your training data contains information about the target, but similar data will not be available when the model is used for prediction.
This leads to high performance on the training set (and possibly even the validation data), but the model will perform poorly in production.

There are two main types of leakage
- **target leakage**
- **train-test contamination**

## Target leakage

Target leakage occurs when your predictors include data that will not be available at the time you make predictions. 

To prevent this type of data leakage, any variable updated (or created) after the target value is realized should be excluded.

![image](https://user-images.githubusercontent.com/74973306/104686956-a654d400-5741-11eb-999a-962a15f54c3d.png)


## Train-Test Contamination

A different type of leak occurs when you aren't careful to distinguish training data from validation data.

Recall that validation is meant to be a measure of how the model does on data that it hasn't considered before. You can corrupt this process in subtle ways if the validation data affects the preprocessing behavior. This is sometimes called **train-test contamination**.


## Example

```python
'''
Number of rows in the dataset: 1319
'''
```
| reports | age | income   | share  | expenditure | owner      | selfemp | dependents | months | majorcards | active |    |
|---------|-----|----------|--------|-------------|------------|---------|------------|--------|------------|--------|----|
| 0       | 0   | 37.66667 | 4.5200 | 0.033270    | 124.983300 | True    | False      | 3      | 54         | 1      | 12 |
| 1       | 0   | 33.25000 | 2.4200 | 0.005217    | 9.854167   | False   | False      | 3      | 34         | 1      | 13 |
| 2       | 0   | 33.66667 | 4.5000 | 0.004156    | 15.000000  | True    | False      | 4      | 58         | 1      | 5  |
| 3       | 0   | 30.50000 | 2.5400 | 0.065214    | 137.869200 | False   | False      | 0      | 25         | 1      | 7  |
| 4       | 0   | 32.16667 | 9.7867 | 0.067051    | 546.503300 | True    | False      | 2      | 64         | 1      | 5  |

```python
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

# Since there is no preprocessing, we don't need a pipeline (used anyway as best practice!)
my_pipeline = make_pipeline(RandomForestClassifier(n_estimators=100))
cv_scores = cross_val_score(my_pipeline, X, y, 
                            cv=5,
                            scoring='accuracy')

print("Cross-validation accuracy: %f" % cv_scores.mean())

[output]
'''
Cross-validation accuracy: 0.978776
'''
```

With experience, you'll find that it's very rare to find models that are accurate 98% of the time. It happens, but it's uncommon enough that we should inspect the data more closely for target leakage.

Here is a summary of the data, which you can also find under the data tab:

- card: 1 if credit card application accepted, 0 if not
- reports: Number of major derogatory reports
- age: Age n years plus twelfths of a year
- income: Yearly income (divided by 10,000)
- share: Ratio of monthly credit card expenditure to yearly income
- expenditure: Average monthly credit card expenditure
- owner: 1 if owns home, 0 if rents
- selfempl: 1 if self-employed, 0 if not
- dependents: 1 + number of dependents
- months: Months living at current address
- majorcards: Number of major credit cards held
- active: Number of active credit accounts  

A few variables look suspicious. For example, does expenditure mean expenditure on this card or on cards used before appying?

At this point, basic data comparisons can be very helpful:

```python
expenditures_cardholders = X.expenditure[y]
expenditures_noncardholders = X.expenditure[~y]

print('Fraction of those who did not receive a card and had no expenditures: %.2f' \
      %((expenditures_noncardholders == 0).mean()))
print('Fraction of those who received a card and had no expenditures: %.2f' \
      %(( expenditures_cardholders == 0).mean()))

[output]
'''
Fraction of those who did not receive a card and had no expenditures: 1.00
Fraction of those who received a card and had no expenditures: 0.02
'''
```

```python
# Drop leaky predictors from dataset
potential_leaks = ['expenditure', 'share', 'active', 'majorcards']
X2 = X.drop(potential_leaks, axis=1)

# Evaluate the model with leaky predictors removed
cv_scores = cross_val_score(my_pipeline, X2, y, 
                            cv=5,
                            scoring='accuracy')

print("Cross-val accuracy: %f" % cv_scores.mean())

[output]
'''
Cross-val accuracy: 0.828650
'''
```

## Conclusion
Data leakage can be multi-million dollar mistake in many data science applications. Careful separation of training and validation data can prevent train-test contamination, and pipelines can help implement this separation. Likewise, a combination of caution, common sense, and data exploration can help identify target leakage.
