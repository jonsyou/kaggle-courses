[tutorial url](https://www.kaggle.com/alexisbcook/cross-validation)

# Cross-Validation

In cross-validation, we run our modeling process on different subsets of the data to get multiple measures of model quality.

![image](https://user-images.githubusercontent.com/74973306/104670342-fff7d700-571e-11eb-8e1b-fe4291d85290.png)

* Holdout  

![image](https://user-images.githubusercontent.com/74973306/104670471-3b92a100-571f-11eb-892f-a34ac2c8ca9e.png)

## Setup

```python
import pandas as pd

# Read the data
data = pd.read_csv('../input/melbourne-housing-snapshot/melb_data.csv')

# Select subset of predictors
cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']
X = data[cols_to_use]

# Select target
y = data.Price
```
- preprocessing
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),
                              ('model', RandomForestRegressor(n_estimators=50,
                                                              random_state=0))
                             ])
```

## Cross-Validation

```python
from sklearn.model_selection import cross_val_score

# Multiply by -1 since sklearn calculates *negative* MAE
scores = -1 * cross_val_score(my_pipeline, X, y,
                              cv=5,
                              scoring='neg_mean_absolute_error')

print("MAE scores:\n", scores)
```
```python
[output]
'''
MAE scores:
 [301628.7893587  303164.4782723  287298.331666   236061.84754543
 260383.45111427]
'''
```
- In this case, we chose negative mean absolute error (MAE) in the ```scoring``` parameter.


```python
print("Average MAE score (across experiments):")
print(scores.mean())
```

```python
[output]
'''
Average MAE score (across experiments):
277707.3795913405
'''
```
---
### Excercise

```python
def get_score(n_estimators):
    my_pipeline = Pipeline(steps=[
        ('preprocessor', SimpleImputer()),
        ('model', RandomForestRegressor(n_estimators, random_state=0))
    ])
    scores = -1 * cross_val_score(my_pipeline, X, y,
                                  cv=3,
                                  scoring='neg_mean_absolute_error')
    return scores.mean()
```

```python
results = {}
for i in range(1,9):
    results[50*i] = get_score(50*i)
```

```python
import matplotlib.pyplot as plt
%matplotlib inline

plt.plot(list(results.keys()), list(results.values()))
plt.show()
```

output

![image](https://user-images.githubusercontent.com/74973306/104671401-14d56a00-5721-11eb-8cbd-f14694db79c5.png)

```python
n_estimators_best = min(results, key=results.get)
```
